# 1.2 알고리즘의 성능

&#x20; 알고리즘은 데이터를 처리하는 근본적인 해결책 중 하나입니다. 과거에는 컴퓨터의 HW 자원의 성능이 좋지 않았기 때문에 이러한 데이터 관리와 처리는 매우 중요한 요소였습니다. 현대에 HW 자원이 매우 강력해졌지만, 그만큼 처리하는 데이터 양이 방대해졌기 때문에 알고리즘의 성능은 아직도 중요합니다.

&#x20; 앞 장에서도 말씀드린 것처럼 자료구조의 연산들도 일종의 알고리즘이기 때문에 자료구조의 성능은 해당 자료구조에 포함된 연산들의 성능으로 판단합니다.

&#x20; 그렇다면 어떤 알고리즘의 "성능이 좋다"거나 "효율적이다"라고 말하는 기준은 무엇이 될까요? 우리가 보통 효율성을 말할 때는 이익 대비 비용을 고려합니다. 그런데 앞 장에서 말씀드린 것처럼 알고리즘은 반드시 정확해야 하므로 이익에는 변동이 있을 수 없습니다. 따라서 알고리즘의 성능을 얘기할 때는 주로 비용을 얘기하며, 알고리즘의 비용은 **시간**과 **공간**이라는 두 관점으로 계산합니다.

&#x20; 먼저, **시간에 대한 성능 척도는 "알고리즘이 걸리는데 얼마나 걸리는가"**입니다. 당연히 알고리즘이 빠를 수록 컴퓨터에 들어가는 전력, 문제를 해결하는데 필요한 시간 자원 등이 감소하니 중요하겠죠.

&#x20; **공간에 대한 성능 척도는 "얼마나 많은 저장 공간이 필요한가"**입니다. 컴퓨터가 데이터를 저장하는 공간은 CPU의 레지스터, 주 메모리 RAM, HDD와 SDD 같은 보조 메모리가 있습니다. 하지만 CPU에서 데이터를 사용할 때 HDD와 SDD에 저장된 데이터를 사용하는 것은 굉장히 시간 소모가 큽니다. 그렇다고 레지스터에 있는 데이터만 사용하자니 레지스터는 용량이 너무 작습니다. 그래서 우리는 주로 RAM 용량을 중요하게 생각합니다. 실제로 프로그램이 수행 중인, 또는 수행 가능한 프로세스가 되는 기준은 RAM에 올려졌는가입니다. RAM이 레지스터보다는 용량이 크지만 제한적이므로, 저장 공간을 효율적으로 사용하는 것은 중요합니다.

&#x20; 그렇다면 이러한 성능은 어떻게 계산되고 분석될까요? 실험적 분석 방법과 이론적 분석 방법으로 나뉩니다.



***

## 실험적 분석 방법

&#x20; _**실험적 분석 방법(Experimental studies)**_는 알고리즘을 실제로 실행하고 측정 및 분석하는 방법입니다. 다양한 경우에 대해서 알고리즘을 테스트하는 것이라고 생각하시면 됩니다.



### 실험 데이터

&#x20; 많은 논문 및 연구에서는 이를 위해 크게 2가지 데이터를 사용하며, 첫번째는 _**실제 데이터(Real data)**_입니다. 먼저, 실제 데이터는 현실 세계에서 제작된 데이터를 의미합니다. 가령, 우리가 단어들을 정렬하는 알고리즘을 테스트한다고 한다면 현실에서 자주 나타나는 단어들을 모아 놓은 데이터나 책들을 사용할 수 있겠죠.

&#x20; 두번째는 _**랜덤 데이터(Random data)**_입니다. 랜덤 데이터는 입력 데이터를 랜덤으로 생성하는 데이터를 의미합니다. 앞선 정렬 알고리즘을 예시로 한다면, 각 단어의 길이와 구성하는 문자를 랜덤으로 구성하여 만들 수 있겠죠. 물론 알고리즘의 실질적인 성능 측정을 위해서는 실제 데이터를 사용한 분석이 좋겠지만 우리가 예상하지 못한 이례적인 데이터도 처리해야 할 수 있기 때문에 랜덤 데이터를 사용한 분석도 유용합니다.

&#x20; 이러한 데이터들을 테스트 케이스(Test case)로써 사용하여 입력으로 가공합니다. 랜덤 데이터는 애초에 입력 형태로 데이터를 만들지만, 앞선 실제 데이터의 책들은 단어들을 랜덤으로 추출하는 등의 가공을 할 수도 있겠죠.



### 실험적 분석 방법의 단점

&#x20; 이러한 실험적 분석 방법은 알고리즘의 성능 측정을 위해 매우 중요하지만, 매우 치명적인 단점들이 존재합니다.

1. **실제로 구현하기 매우 어려울 수 있다.**

&#x20; 앞으로 우리가 공부할 알고리즘들은 매우 간단한 편에 속합니다. 이보다 C나  gcc, Python 등의 표준 라이브러리들에서 사용되는 알고리즘들이 복잡하지만 어느 정도 노력을 기울이면 구현 자체는 할 수 있습니다~~_(구현을 했으니 라이브러리로 존재하겠죠)_~~. 하지만 학계에서 연구하고 있는 알고리즘들이나 실제로 개발 중의 특정한 문제를 해결하기 위해 최적화한 알고리즘 등은 한도 끝도 없이 복잡해질 수 있습니다.

&#x20; 그러나 구현 자체도 시간과 인적 비용이 요구되므로 복잡한 알고리즘을 구현하는 것 자체가 비용을 발생시키며, 정말로 구현하기 어려운 알고리즘들이 많습니다.



2. **실험을 진행한 케이스 외의 성능을 알 수 없다.**

&#x20; 우리가 데이터를 통해 만든 테스트 케이스 외의 경우는 알 수 없습니다. 심지어 우리의 테스트 케이스가 중요한 엣지 케이스(Edge case)를 포함하지 않는다면 추후 치명적인 성능 이슈를 발생시킬 수 있습니다.

{% hint style="info" %}
_**엣지 케이스(Edge case, Corner case)**_는 일반적인 경우와 다르거나 예외적인 테스트 케이스를 의미하며, 알고리즘의 성능 및 정확도 측정에서 중요한 역할을 합니다. 매우 복잡한 도로들로 구성된 도시에서 길을 찾는 알고리즘을 개발한다고 가정해봅시다. 이때, 교차로가 일종의 분기가 될 것이며, 매우 복잡한 도로들이므로 교차로에 연결된 도로가 매우 많을 것입니다. 이러한 경우, 막다른 길이나 다시 똑같은 곳으로만 돌아오는 도로들이 있는 경우가 엣지 케이스가 될 수 있을 것입니다.
{% endhint %}

{% hint style="info" %}
잘 알려진 문제들은 잘 만들어진 _**벤치마크(Benchmark)**_를 사용합니다. 이러한 벤치마크들은 현실에서의 발생 빈도, 엣지 케이스를 비롯한 매우 광범위한 테스트 케이스 등의 속성을 가지고 있습니다. 이러한 벤치마크들을 잘 만들기 위한 연구들도 진행되고 있습니다.
{% endhint %}



3. **HW 및 SW 환경에 의존적이다.**

&#x20; 실험적 분석 방법의 치명적인 단점 중 하나는 HW 및 SW 환경에 의존적이라는 것입니다. 우리가 흔히 실험을 할 때는 독립 변수와 종속 변수를 나누어 관리합니다. 알고리즘을 실험할 때는 당연히 알고리즘을 수행하는 프로그램만이 독립 변수로 작용해야 합니다. 그러나 인간이 조정하고 측정하는 것이 불가능하거나 어려운 많은 요소들이 존재합니다.

&#x20; HW적으로는 크게는 컴퓨터 기종 및 부품의 차이 등이 있으며 작게는 CPU와 RAM의 물리적 거리, 충전기의 출력 등 매우 사소한 것도 영향을 미치게 됩니다. SW적으로는 컴퓨터가 수행 중인 다른 프로그램들이 영향을 미칠 수 있으며, 심지어 OS(Operating system)도 영향을 미칩니다. 하다못해, 알고리즘을 수행하는 파일의 위치와 실제 수행할 때 저장되는 메모리 상의 위치 등도 영향을 미치게 됩니다.

&#x20; 이러한 다양한 이유들로 인해 다른 알고리즘 간의 성능 비교가 어려우며, 같은 알고리즘에 대해서도 성능 차이가 발생할 수 있습니다.

{% hint style="info" %}
그래서 알고리즘 논문들은 실험 결과를 기재할 때, 어떤 CPU, RAM, OS, 컴파일러, 최적화 버전 등에서 수행했는지 기재합니다.
{% endhint %}



***

## 이론적 분석 방법

&#x20; _**이론적 분석 방법(Theoretical analysis)**_는 앞서 언급한 실험적 분석 방법의 단점들을 모두 해결합니다. 실제로 알고리즘을 구현하지 않고 가상의 수행 시간과 공간의 사용 크기를 계산합니다. 테스트 케이스들을 일반화하여 입력의 크기에 대한 함수의 형태로 분석합니다. 그러므로 모든 경우에 대한 성능 지표를 제공하며, 환경에 독립적입니다. 정확하게 표현하면 아래 단계를 거칩니다.

1. 의사코드(Pseudocode)를 작성한다.
2. 알고리즘이 수행하면서 실행하는 연산의 수를 센다.
3. 이를 입력의 크기에 대한 함수로 표현한다.

&#x20; 한 단계가 더 있긴 하지만, 그건 다음 장에서 더 다루도록 하죠. 하나하나 해볼까요?



### 의사 코드

<figure><img src="../.gitbook/assets/image (2).png" alt=""><figcaption><p>최댓값 찾기 의사코드</p></figcaption></figure>

&#x20; 먼저, C, Python과 같이 우리가 사용하는 High-level 언어들을 _**의사코드(Pseudocode)**_로 작성해야 합니다. 의사코드는 크게 알고리즘의 이름, 입력, 출력, 알고리즘의 구성으로 이루어집니다. 위 이미지는 데이터들이 일렬로 저장된 형태인 배열에서 가장 큰 값을 찾는 알고리즘의 의사 코드입니다. 맨 위에는 알고리즘의 이름 $$arrayMax$$가 기재되고, 그 아래에 입력과 출력, 알고리즘의 구성 순으로 기재되어 있습니다.

&#x20; 위 이미지에서 보이는 것처럼 의사코드는 우리가 사용하는 프로그래밍 언어들과 유사하며 그에 따라 정해진 몇몇 규칙들이 있습니다. 이러한 규칙들은 일종의 관행으로 여겨지므로 사람마다 작성하는 방식은 다를 수 있습니다. 그럼에도 다 한눈에 알아볼 수 있으니 걱정할 필요는 없습니다. 몇몇 헷갈릴 수 있는 기호들은 아래 표를 참고해주세요.

<table data-full-width="false"><thead><tr><th width="161.5">기호</th><th>설명</th></tr></thead><tbody><tr><td><span class="math"> \leftarrow </span></td><td>할당 연산(Assignment operation). <span class="math"> A \leftarrow B </span>는 변수 <span class="math">B</span>의 값을 <span class="math">A</span>에 할당한다는 의미이다.</td></tr><tr><td><span class="math"> = </span></td><td>동등 비교 연산(Equality comparision operation).</td></tr><tr><td><span class="math"> \textrm{for }...\textrm{ do } ...</span></td><td>[반복문] <span class="math">\textrm{for}</span>와 <span class="math">\textrm{do}</span> 사이에는 반복되는 조건이, <span class="math">\textrm{do}</span> 뒤에는 반복 수행될 코드가 작성되며 들여쓰기로 구분된다.</td></tr><tr><td><span class="math"> \textrm{while }...\textrm{ do } ... </span></td><td>[반복문] <span class="math">\textrm{for}</span>&#x26;<span class="math">\textrm{do}</span>와 동일</td></tr><tr><td><span class="math">\textrm{repeat }...\textrm{ until } ...</span></td><td>[반복문] <span class="math">\textrm{repeat}</span>과 <span class="math">\textrm{until}</span> 사이에는 반복 수행될 코드가 작성되며 들여쓰기로 구분된다. <span class="math">\textrm{until}</span> 뒤에는 조건이 작성된다.</td></tr></tbody></table>

&#x20; 이러한 규칙들이 있지만, 의사코드는 High-level description이므로 프로그래밍 언어들이나 컴파일러, 컴퓨터에 종속된 여러 요소들을 무시합니다. 위 최댓값 찾기의 의사 코드를 보면 변수들의 자료형을 고려하지 않으며 선언도 제대로 하지 않고 사용하기도 합니다.

{% hint style="info" %}
컴퓨터공학에서 프로그래밍 언어나 표현에 대해 High-level, Low-level이라고 하는 것은 인간 또는 기계에 얼마나 친화적인가라고 생각하시면 됩니다. 높은 수준일수록 컴퓨터의 특징이나 속성에 대한 것들을 숨깁니다. 보통 **추상화(Abstraction)**한다고 합니다. 예를 들어, Python은 높은 수준의 언어라고 할 수 있으며, 컴퓨터가 이해하는 0과 1로 구성된 기계어는 가장 낮은 수준의 언어라고 할 수 있습니다.

언어들은 실제로 프로그래밍에 사용되므로, 컴퓨터 시스템의 많은 것들을 신경써야 합니다. 그것을 아무리 추상화했다고 해도 말이죠. 그러므로 의사코드는 굉장히 높은 수준의 표현이라고 할 수 있겠죠.
{% endhint %}



### 수행 연산 세기와 가상 머신

&#x20; 자, 의사코드도 작성했겠다, 우리는 이제 작성한 의사코드의 연산들을 직접 세서 이 알고리즘이 작동하는 시간을 계산하고 공간도 계산할 겁니다. 그런데 어떻게 연산을 세야 할까요? 할당 연산과 덧셈은 수행시간이나 활용하는 공간이 똑같나요? 덧셈과 나눗셈 마저도 실제로는 차이가 나타나는데 말이죠.

&#x20; 이러한 문제를 신경 쓰지 않기 위해 우리는 _가상의 컴퓨터를 가정하고, 이 가상머신에서 매우 짧은 시간에 수행되는 연산들을 세고자 합니다._ 이러한 가상의 컴퓨터, CPU 모델을 _**RAM(Random Access Machine)**_이라고 하며, 우리가 셀 연산들은 _**기본 연산(Primitive opertaion)**_이라고 합니다.



#### Random Access Machine & Primitive operations

&#x20; RAM은 다음과 같은 속성을 가집니다.

* **데이터를 저장하는 공간인 레지스터(Register)가 무한합니다.** 이 자료를 읽는 많은 분들은 레지스터가 정확히 뭔지 모를 수 있습니다. 그냥 메모리가 무한하다고 생각하면 됩니다.
* **각 메모리 셀은 임의의 문자나 숫자와 같은 단위 데이터를 저장할 수 있습니다.** 실제 컴퓨터와 다른 점은 자료형마다 다르게 처리를 해주는 등의 일은 하지 않습니다. 그냥 추상적으로 숫자나 문자 등을 하나의 셀에 저장하게 됩니다. 다만, 문자열은 문자의 배열로 취급됩니다.
* **모든 메모리 셀은 색인(Indexing)이 되어 있어서 단위 시간 안에 접근할 수 있습니다.** 이러한 이유는 데이터가 저장되는 공간이 레지스터이므로 매우 빠르게 접근 가능하기 때문입니다.

&#x20; 여기서 **단위 시간**은 그냥 아주 빠른 시간으로 고려도 할 필요 없는 시간 정도로 이해하시면 됩니다. RAM의 두번째 속성으로 인해 우리는 잡다한 한계를 무시할 수 있습니다. 또한, 첫번째, 세번째 속성으로 인해 RAM에서는 모든 연산이 기계적 요인(메모리 접근 시간 등)으로부터 독립적이게 됩니다. 그러므로 어떤 연산들이 단위 시간에 수행된다면 수행 시간에 있어서 동일하다고 볼 수 있으며, 이러한 연산들을 **기본 연산(Primitive operation)**이라고 합니다. 아래 표는 일반적인 기본 연산들을 소개하고 있습니다.

<table><thead><tr><th width="165">종류</th><th>예시</th></tr></thead><tbody><tr><td>사칙연산</td><td>+, -, *, /, %(mod, 나머지)</td></tr><tr><td>할당</td><td><span class="math">\leftarrow</span></td></tr><tr><td>비교</td><td><span class="math">></span>, <span class="math">\geq</span>, <span class="math">=</span>, <span class="math">\neq</span>, <span class="math">\leq</span>, <span class="math">&#x3C;</span></td></tr><tr><td>인덱싱 (접근)</td><td>[ ]</td></tr><tr><td>함수호출</td><td><span class="math">\textrm{mad}(x,y)</span></td></tr><tr><td>반환</td><td><span class="math">\textrm{return}</span></td></tr></tbody></table>

&#x20; 자, 그러면 이걸 앞선 최댓값 찾기 예시에 적용해볼까요?



### 입력 크기에 대한 함수로 표현

<figure><img src="../.gitbook/assets/image (3).png" alt=""><figcaption><p>최댓값 찾기 의사코드</p></figcaption></figure>

&#x20; 우리는 기본 연산을 세서 입력의 크기인 $$n$$에 대한 함수로 사용하는 시간과 사용하는 (메모리) 공간을 표현할 것입니다. 먼저, 시간을 해보죠.

* **line 1**: 한번의 인덱싱 - $$A[0]$$, 한번의 할당 - $$currentMax\leftarrow A[0]$$

&#x20; line 2부터 line 4까지는 반복문입니다. 여러 번 수행되므로 각 줄이 몇 번이나 수행되는지 계산해야 합니다. 하나하나 해봅시다.

* **line 2**: 먼저 변수 $$i$$에 1을 할당합니다. 그리고 반복문의 수행이 끝날 때마다 $$i$$에 1을 더해서 $$n$$까지 더할 겁니다. 왜냐면 보통 우리의 컴퓨터는 $$i$$의 값이 $$n-1$$일 때의 반복문을 수행한 후, $$i$$의 값을 $$n$$으로 만든 후 범위를 벗어났다고 판단하여 반복문을 종료하기 때문입니다. 그러므로 $$i$$에 대한 $$+1$$연산이 총 $$n-1$$번 수행됩니다. 그리고 반복문을 수행하기 전에 $$i$$의 값이 요구되는 범위에 있는지 파악해야 하므로 1번의 비교 연산($$i<n$$)이 수행될 것입니다. **정리하자면, 1번의 할당 연산,** $$n-1$$**의 덧셈 연산,** $$n$$**번의 비교 연산을 수행하므로 총** $$2n$$**의 기본 연산이 수행됩니다.**

{% hint style="info" %}
line 2에 대한 설명에서 $$i$$를 $$n$$까지 더하는지 $$n-1$$까지 더하는지는 헷갈릴 수 있습니다. 실질적으로는 어떻게 코딩하냐에 따라 다르고, 두 경우 모두 정상적으로 작동하겠죠.

```c
for (int i = 1; i < n; i++)
```

위와 같이 코드를 짠다면 $$i$$를 $$n$$까지 더하겠지만,

```c
for (int i = 1; i <= n; i++)
```

위와 같이 코드를 짠다면 $$i$$를 $$n-1$$까지 더하겠죠.

다음 장에서 이러한 차이는 무의미하다는 것을 공부할 것입니다.
{% endhint %}

&#x20; 참고로, line 2이 $$2n$$번의 기본 연산을 수행하는 것과는 반대로 line 3과 line 4은 $$i$$가 1일 때부터 $$n-1$$일 때까지 수행되므로, 총 $$n-1$$번 반복합니다.

* **line 3**: 한번의 인덱싱 - $$A[i]$$, 한번의 비교 연산 - $$A[i]>currentMax$$
* **line 4**: line 5와 동일

&#x20; line 3과 line 4은 각각 2번의 기본 연산을 수행합니다. 그러나 앞서 말씀드린 것처럼 $$n-1$$번 반복하므로 둘다 총 $$2(n-1)$$번의 기본 연산을 수행합니다. line 5는 반환만 하므로 1번의 기본 연산을 수행하겠죠. 그럼 알고리즘이 수행하는 기본 연산의 총 횟수는 $$2+2n+2(n-1)+2(n-1)+1=6n-1$$이 됩니다.

&#x20; 최댓값 찾기에서 공간 세기는 비교적 쉽습니다. 배열 $$A$$와 그 크기 $$n$$은 입력으로 주어지므로 알고리즘이 수행되기 위해 고려할 공간은 아닙니다. 실제로 알고리즘이 요구하는 공간은 최댓값을 저장하는 변수 $$currentMax$$와 반복문의 $$i$$입니다. 그러므로 필요한 공간은 2가 됩니다.

&#x20; 그런데 그런 의문이 드시겠죠. "아니, line 4은 line 3에서의 조건문에 해당하지 않으면 수행되지 않을텐데 왜 다 세냐?" 왜냐하면 우리는 지금 최악의 경우(Worst case)에 대해서 분석하고 있기 때문입니다.



### 3가지 경우

&#x20; 알고리즘을 분석할 때는 어떤 '경우'를 따지느냐는 굉장히 중요합니다. 왜냐하면 입력에 따라 실제로 알고리즘이 수행하는 연산의 횟수가 달라지기 때문입니다. 앞서 계속 얘기했던 최댓값 찾기를 생각해봅시다. 만약 입력 배열 $$A$$가 $$[5,4,3,2,1]$$이라면 line 3의 if문의 조건을 한번도 만족하지 않겠죠. 하지만 $$A$$가 $$[1,2,3,4,5]$$라면 항상 line 3의 if문의 조건을 만족해서 line 4가 실행될 것입니다.

&#x20; 그래서 우리는 입력을 크게 3가지 경우로 나눕니다.

<table><thead><tr><th width="135">Case</th><th>설명</th></tr></thead><tbody><tr><td>Best</td><td>알고리즘이 가장 빨리 수행되거나 가장 적은 공간을 사용하는 경우</td></tr><tr><td>Average</td><td>Best와 Worst가 아닌 경우</td></tr><tr><td>Worst</td><td>알고리즘이 가장 느리게 수행되거나 가장 많은 공간을 사용하는 경우</td></tr></tbody></table>

&#x20; 먼저 _최선의 경우(Best case)_는 알고리즘이 가장 효율적으로 수행되는 입력입니다. Best case는 발생 빈도가 높지 않고, 분석의 가치가 낮기 때문에 보통 분석의 대상이 되지 않습니다.

&#x20; _최악의 경우(Worst case)_는 알고리즘이 가장 비효율적으로 수행되는 입력입니다. 분석의 가치가 높으며 분석하기도 쉽습니다. 또한, 현실에서의 시간적 한계와 공간적 한계에 적용되므로 매우 중요합니다.

&#x20; _평균의 경우(Average case)_는 Best case와 Worst case가 아닌 모든 경우를 의미합니다. 일반적으로 확률을 통해 분석됩니다. 종종 분석하는 것이 어려운 경우가 있지만 실제로 알고리즘이 동작할 때의 효율성을 의미하므로 분석에 사용됩니다.

&#x20; 이러한 특징을 가지고 있기 때문에 우리는 앞서 최댓값 찾기의 기본 연산을 계산할 때 Worst case를 기준으로 센 것입니다. 앞으로도 주로 Worst case를 기준으로 분석해나갈 것이며, 간혹 Average case도 분석하게 될 것입니다.



{% hint style="info" %}
간혹, 사람들이 오해하는 부분이 Worst case만을 유의미하다고 생각하는 것입니다. 일반적으로 Worst case에서 더 효율적으로 작동하는 알고리즘이 더 좋다고 평가되기는 합니다. 하지만 앞서 말씀드린 것처럼  Average case에서 더 좋은 성능을 나타내는 알고리즘은 실용적인 면이 강합니다.

정렬 문제(Sorting problem)을 해결하는 알고리즘 중에는 Quick sort algorithm이 있습니다. 이 알고리즘은 Worst case에서는 매우 느리지만, Average case에서는 매우 빠르게 문제를 해결합니다. 그래서 많은 라이브러리에서 이 알고리즘을 활용하고 있습니다.
{% endhint %}

***

&#x20; 다시 최댓값 찾기 예시를 봅시다. 수행하는 기본 연산의 횟수는 $$6n-1$$이었고, 사용하는 공간은 2였습니다. 그러나 이 분석은 가상의 환경에서의 분석이므로, 우리는 이 결과를 최댓값 찾기의 정확한 성능으로 볼 수는 없습니다. 그래서 현실에 맞추기 위해 한 단계의 과정을 더 거치게 됩니다.

